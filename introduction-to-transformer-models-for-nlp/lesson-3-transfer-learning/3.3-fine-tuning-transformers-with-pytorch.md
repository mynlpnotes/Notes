# 3.3 Fine tuning Transformers with PyTorch

**Fine tuning with native PyTorch:**

*

    <figure><img src="../../.gitbook/assets/image (58).png" alt=""><figcaption></figcaption></figure>
* We start with some training data and we use that training data to update a model
* Model is computing a loss using a loss function, and then uses that to compute gradients, which are used to optimize weights, which updates the model as a whole
* This continues till we are satisfied with the performance
*

    <figure><img src="../../.gitbook/assets/image (59).png" alt=""><figcaption></figcaption></figure>

***

**Fine tuning with Hugging face trainer:**

*

    <figure><img src="../../.gitbook/assets/image (60).png" alt=""><figcaption></figcaption></figure>
* The entire training loop is encapsulated in hugging face trainer API

**Dataset:**

* Holds all data and splits into training/testing sets

**DataCollator:**

* Forms batches of data from Datasets

**Training Arguments:**

* Keeps track of data from Datasets

**Trainer:**

* API to the Pytorch training loop for most standard cases
*

    <figure><img src="../../.gitbook/assets/image (61).png" alt=""><figcaption></figcaption></figure>
